{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wjNCbjAJQkt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "data_dir =  \"/content/drive/MyDrive/dataset/sih_road_dataset\"\n",
        "labels = [\"good\", \"poor\", \"satisfactory\", \"very_poor\"]\n",
        "x = []\n",
        "y = []\n",
        "for label in labels:\n",
        "    data = os.path.join(data_dir,label)\n",
        "    for image in os.listdir(data):\n",
        "        try:\n",
        "            im = cv2.imread(os.path.join(data,image),cv2.IMREAD_COLOR)\n",
        "            im = cv2.resize(im,(224,224))\n",
        "            \n",
        "            x.append(im)\n",
        "            y.append(labels.index(label))\n",
        "            \n",
        "            \n",
        "        except Exception as e:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)        \n",
        "len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdLPJlipKu_P",
        "outputId": "4b6fd87c-9ad9-415c-e9d8-d20cd9851ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2081"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.unique(y)\n",
        "np.unique(x)\n",
        "\n",
        "x = np.array(x)/255.0\n",
        "y = np.array(y)\n",
        "\n",
        "x.shape\n",
        "y.shape\n",
        "\n",
        "x = x.reshape(-1, 224, 224, 3)\n",
        "x.shape\n",
        "y = y.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "hrT3nAuVKyhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y,4,)\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagenerator = ImageDataGenerator(\n",
        "fill_mode= 'nearest',\n",
        "horizontal_flip=False,\n",
        "vertical_flip=False,\n",
        "shear_range=0.1,\n",
        "zoom_range = 0.1, # Randomly zoom image \n",
        "width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "height_shift_range=0.2\n",
        ")\n",
        "datagenerator.fit(x)"
      ],
      "metadata": {
        "id": "fU3SCfMnLNLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HPNWa4d4suqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y)"
      ],
      "metadata": {
        "id": "Rq8qXdpKLTbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.Conv2D(32,(5,5),padding ='same',strides=(2,2),activation='relu',input_shape=(224,224,3)),\n",
        "tf.keras.layers.MaxPooling2D((2,2)),\n",
        "tf.keras.layers.Conv2D(64,(5,5),padding ='same',strides=(2,2),activation='relu'),\n",
        "tf.keras.layers.MaxPooling2D((2,2)),\n",
        "tf.keras.layers.Conv2D(128,(5,5),padding ='same',strides=(2,2),activation='relu'),\n",
        "tf.keras.layers.MaxPooling2D((2,2)),\n",
        "tf.keras.layers.Conv2D(128,(5,5),padding ='same',strides=(2,2),activation='relu'),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(256,activation='relu'),\n",
        "tf.keras.layers.Dropout(0.3),\n",
        "    \n",
        "tf.keras.layers.Dense(4,activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DlWknVD5LZHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(datagenerator.flow(x_train,y_train,batch_size=32),epochs=20,validation_data=datagenerator.flow(x_test,y_test))"
      ],
      "metadata": {
        "id": "y3mxZFpNLj-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "mg_path = '/content/30ac06c4-8054-431d-ad1c-7b531dedfa86.jpg'\n",
        "#plt.imshow(mg_path)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "tlKbgalw6o4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img(mg_path, target_size=(224, 224))"
      ],
      "metadata": {
        "id": "YmqNpkZQ8bv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_array = image.img_to_array(img)\n",
        "img_batch = np.expand_dims(img_array, axis=0)"
      ],
      "metadata": {
        "id": "eeACd_L-82hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#img_preprocessed = preprocess_input(img_batch)\n",
        "prediction = model.predict(img_batch)\n",
        "s=np.argmax(prediction)\n",
        "labels = [\"good\", \"poor\", \"satisfactory\", \"very_poor\"]\n",
        "print(labels[s])"
      ],
      "metadata": {
        "id": "ZjzsCNSA87fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KeF3XBU-TxFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ynew=model.predict(x_test)\n",
        "#model.predict_classes(ynew)\n",
        "np.argmax(ynew[1])\n"
      ],
      "metadata": {
        "id": "K1yslRyLlaVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "n57qm2sWnrQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflowjs"
      ],
      "metadata": {
        "id": "jAQl2TN9SNfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "# pip install tensorflowjs\n",
        "import tensorflowjs as tfjs"
      ],
      "metadata": {
        "id": "mVqaaOsG4UQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, suffix=None):\n",
        "  '''\n",
        "  Saves a given model in a models directory and appends a suffix (string)\n",
        "  '''\n",
        "\n",
        "  # Create a model directory pathname with current time\n",
        "  modeldir = os.path.join(\"/content/drive/MyDrive/dataset/sih_road_dataset\")\n",
        "  \n",
        "  model_path = modeldir + '_' + suffix + '.h5' # save format of model\n",
        "  print(f'Saving model to: {model_path}...')\n",
        "  model.save(model_path)\n",
        "  tfjs.converters.save_keras_model(model,model_path)\n",
        "\n",
        "  return model_path"
      ],
      "metadata": {
        "id": "12qstEiPtRu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save_model(model, suffix='full-images-inception-4')\n",
        "save_model(model, suffix='full-images-inception')"
      ],
      "metadata": {
        "id": "D-mMtO9KugKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jQtvWOlOrqwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "file = open( '/content/drive/My Drive/Bird-species-classification/models/fullmodel_2.tflite' , 'wb' ) \n",
        "file.write( tflite_model )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7qUri4dvAcR",
        "outputId": "123c56bd-e720-4b65-d4f2-85b2f8aa303f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp_lshwdvh/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp_lshwdvh/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3206872"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    }
  ]
}